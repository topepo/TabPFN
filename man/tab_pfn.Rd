% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/TabPFN-fit.R
\name{tab_pfn}
\alias{tab_pfn}
\alias{tab_pfn.default}
\alias{tab_pfn.data.frame}
\alias{tab_pfn.matrix}
\alias{tab_pfn.formula}
\alias{tab_pfn.recipe}
\title{Fit a TabPFN model.}
\usage{
tab_pfn(x, ...)

\method{tab_pfn}{default}(x, ...)

\method{tab_pfn}{data.frame}(
  x,
  y,
  num_estimators = 8L,
  softmax_temperature = 0.9,
  balance_probabilities = FALSE,
  average_before_softmax = FALSE,
  training_set_limit = 10000,
  control = control_tab_pfn(),
  ...
)

\method{tab_pfn}{matrix}(
  x,
  y,
  num_estimators = 8L,
  softmax_temperature = 0.9,
  balance_probabilities = FALSE,
  average_before_softmax = FALSE,
  training_set_limit = 10000,
  control = control_tab_pfn(),
  ...
)

\method{tab_pfn}{formula}(
  formula,
  data,
  num_estimators = 8L,
  softmax_temperature = 0.9,
  balance_probabilities = FALSE,
  average_before_softmax = FALSE,
  training_set_limit = 10000,
  control = control_tab_pfn(),
  ...
)

\method{tab_pfn}{recipe}(
  x,
  data,
  num_estimators = 8L,
  softmax_temperature = 0.9,
  balance_probabilities = FALSE,
  average_before_softmax = FALSE,
  training_set_limit = 10000,
  control = control_tab_pfn(),
  ...
)
}
\arguments{
\item{x}{Depending on the context:
\itemize{
\item A \strong{data frame} of predictors.
\item A \strong{matrix} of predictors.
\item A \strong{recipe} specifying a set of preprocessing steps
created from \code{\link[recipes:recipe]{recipes::recipe()}}.
}}

\item{...}{Not currently used, but required for extensibility.}

\item{y}{When \code{x} is a \strong{data frame} or \strong{matrix}, \code{y} is the outcome
specified as:
\itemize{
\item A \strong{data frame} with 1 numeric column.
\item A \strong{matrix} with 1 numeric column.
\item A numeric \strong{vector} for regression or a \strong{factor} for classification.
}}

\item{num_estimators}{An integer for the ensemble size. Default is \code{8L}.}

\item{softmax_temperature}{An adjustment factor that is a divisor in the
exponents of the softmax function (see Details below). Defaults to 0.9.}

\item{balance_probabilities}{A logical to adjust the prior probabilities in
cases where there is a class imbalance. Default is \code{FALSE}. Classification
only.}

\item{average_before_softmax}{A logical. For cases where
\code{num_estimators > 1}, should the average be done before using the softmax
function or after? Default is \code{FALSE}.}

\item{training_set_limit}{An integer greater than 2L (and possibly \code{Inf})
that can be used to keep the training data within the limits of the
data constraints imposed by the Python library.}

\item{control}{A list of options produced by \code{\link[=control_tab_pfn]{control_tab_pfn()}}.}

\item{formula}{A formula specifying the outcome terms on the left-hand side,
and the predictor terms on the right-hand side.}

\item{data}{When a \strong{recipe} or \strong{formula} is used, \code{data} is specified as:
\itemize{
\item A \strong{data frame} containing both the predictors and the outcome.
}}
}
\value{
A \code{tab_pfn} object with elements:
\itemize{
\item \code{fit}: the python object containing the model.
\item \code{levels}: a character string of class levels (or NULL for regression)
\item \code{training}: a vector with the training set dimensions.
\item \code{logging}: any R or python messages produced by the computations.
\item \code{blueprint}: am object produced by \code{\link[hardhat:mold]{hardhat::mold()}} used to process
new data during prediction.
}
}
\description{
\code{tab_pfn()} applies data to a pre-estimated deep learning model defined by
Hollmann \emph{et al} (2025). This model emulates Bayesian inference for
regression and classification models.
}
\details{
\strong{Important Note}. Due to how Python uses the OpenMP library, it is
important that you load your virtual Python environment prior to loading any
R package that also uses OpenMP. If not, a segmentation fault can occur.
See \href{https://github.com/topepo/TabPFN/issues/3}{this GitHub issue}.

Predictors do not require preprocessing; missing values and factor vectors
are allowed.

For the \code{softmax_temperature} value, the softmax terms are:

\preformatted{
exp(value / softmax_temperature)
}

A value of \code{softmax_temperature = 1} results in a plain softmax value.
}
\examples{
predictors <- mtcars[, -1]
outcome <- mtcars[, 1]

# XY interface
mod <- tab_pfn(predictors, outcome)

# Formula interface
mod2 <- tab_pfn(mpg ~ ., mtcars)

# Recipes interface
if (rlang::is_installed("recipes")) {
 library(recipes)
 rec <-
  recipe(mpg ~ ., mtcars) \%>\%
  step_log(disp)

 mod3 <- tab_pfn(rec, mtcars)
 mod3
}

}
\references{
Hollmann, Noah, Samuel Müller, Lennart Purucker, Arjun Krishnakumar, Max
Körfer, Shi Bin Hoo, Robin Tibor Schirrmeister, and Frank Hutter.
"Accurate predictions on small data with a tabular foundation model."
\emph{Nature} 637, no. 8045 (2025): 319-326.

Hollmann, Noah, Samuel Müller, Katharina Eggensperger, and Frank Hutter.
"Tabpfn: A transformer that solves small tabular classification problems in
a second." \emph{arXiv preprint} arXiv:2207.01848 (2022).

Müller, Samuel, Noah Hollmann, Sebastian Pineda Arango, Josif Grabocka, and
Frank Hutter. "Transformers can do Bayesian inference." \emph{arXiv preprint}
arXiv:2112.10510 (2021).
}
